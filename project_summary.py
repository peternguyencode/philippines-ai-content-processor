#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tá»”NG Káº¾T TOÃ€N Bá»˜ Dá»° ÃN - TOOL AI CONTENT PROCESSOR
Liá»‡t kÃª táº¥t cáº£ chá»©c nÄƒng vÃ  dá»¯ liá»‡u hiá»‡n cÃ³
"""

import json
import os
from datetime import datetime

import mysql.connector
from mysql.connector import Error


class ProjectSummary:
    """Tá»•ng káº¿t dá»± Ã¡n"""

    def __init__(self):
        self.connection = None
        self.connect_database()

    def connect_database(self):
        """Káº¿t ná»‘i database"""
        try:
            self.connection = mysql.connector.connect(
                host="localhost",
                port=3308,
                user="root",
                password="baivietwp_password",
                database="mydb",
                charset="utf8mb4",
                autocommit=True,
            )
            return True
        except Error as e:
            print(f"âŒ Lá»—i káº¿t ná»‘i database: {e}")
            return False

    def analyze_data_structure(self):
        """PhÃ¢n tÃ­ch cáº¥u trÃºc dá»¯ liá»‡u"""
        print("ğŸ“Š PHÃ‚N TÃCH Cáº¤U TRÃšC Dá»® LIá»†U")
        print("=" * 50)

        try:
            cursor = self.connection.cursor(dictionary=True)

            # Kiá»ƒm tra báº£ng posts
            cursor.execute("DESCRIBE posts")
            posts_structure = cursor.fetchall()

            print("ğŸ—‚ï¸ Báº¢NG POSTS (Input Data):")
            for field in posts_structure:
                field_info = f"   {field['Field']}: {field['Type']}"
                if field["Null"] == "NO":
                    field_info += " (Required)"
                print(field_info)

            # Kiá»ƒm tra báº£ng posts_ai
            cursor.execute("DESCRIBE posts_ai")
            posts_ai_structure = cursor.fetchall()

            print(f"\nğŸ¤– Báº¢NG POSTS_AI (AI Processing Output):")
            for field in posts_ai_structure:
                field_info = f"   {field['Field']}: {field['Type']}"
                if field["Null"] == "NO":
                    field_info += " (Required)"
                print(field_info)

            cursor.close()

        except Error as e:
            print(f"âŒ Lá»—i phÃ¢n tÃ­ch structure: {e}")

    def analyze_current_data(self):
        """PhÃ¢n tÃ­ch dá»¯ liá»‡u hiá»‡n táº¡i"""
        print(f"\nğŸ“ˆ PHÃ‚N TÃCH Dá»® LIá»†U HIá»†N Táº I")
        print("=" * 50)

        try:
            cursor = self.connection.cursor(dictionary=True)

            # Thá»‘ng kÃª posts
            cursor.execute("SELECT COUNT(*) as total FROM posts")
            total_posts = cursor.fetchone()["total"]

            cursor.execute(
                "SELECT category, COUNT(*) as count FROM posts GROUP BY category"
            )
            category_stats = cursor.fetchall()

            cursor.execute("SELECT COUNT(*) as processed FROM posts_ai")
            processed_posts = cursor.fetchone()["processed"]

            cursor.execute(
                "SELECT processing_status, COUNT(*) as count FROM posts_ai GROUP BY processing_status"
            )
            status_stats = cursor.fetchall()

            print(f"ğŸ“Š Tá»”NG QUAN:")
            print(f"   ğŸ’¾ Tá»•ng posts cÃ³ sáºµn: {total_posts}")
            print(f"   âœ… ÄÃ£ AI processing: {processed_posts}")
            print(f"   â³ ChÆ°a xá»­ lÃ½: {total_posts - processed_posts}")

            print(f"\nğŸ“‚ PHÃ‚N Bá» THEO DANH Má»¤C:")
            for cat in category_stats:
                print(f"   ğŸ“ {cat['category']}: {cat['count']} posts")

            if status_stats:
                print(f"\nğŸ”„ TRáº NG THÃI AI PROCESSING:")
                for status in status_stats:
                    print(
                        f"   ğŸ¯ {status['processing_status']}: {status['count']} posts"
                    )

            cursor.close()

        except Error as e:
            print(f"âŒ Lá»—i phÃ¢n tÃ­ch dá»¯ liá»‡u: {e}")

    def show_sample_data(self):
        """Hiá»ƒn thá»‹ dá»¯ liá»‡u máº«u"""
        print(f"\nğŸ“‹ Dá»® LIá»†U MáºªU")
        print("=" * 50)

        try:
            cursor = self.connection.cursor(dictionary=True)

            # Sample posts gá»‘c
            cursor.execute(
                """
                SELECT id, title, category, 
                       LENGTH(content) as content_length,
                       created_date 
                FROM posts 
                LIMIT 5
            """
            )
            sample_posts = cursor.fetchall()

            print("ğŸ“ POSTS Gá»C (Sample 5):")
            for post in sample_posts:
                print(f"   #{post['id']}: {post['title'][:60]}...")
                print(f"      ğŸ“‚ Category: {post['category']}")
                print(f"      ğŸ“Š Content: {post['content_length']} chars")
                print(f"      ğŸ“… Date: {post['created_date']}")
                print()

            # Sample AI processed posts
            cursor.execute(
                """
                SELECT pa.post_id, pa.title, pa.processing_status,
                       pa.ai_model, pa.image_url,
                       LENGTH(pa.ai_content) as ai_content_length
                FROM posts_ai pa 
                ORDER BY pa.updated_date DESC
                LIMIT 3
            """
            )
            ai_sample = cursor.fetchall()

            if ai_sample:
                print("ğŸ¤– AI PROCESSED POSTS (Sample 3):")
                for ai_post in ai_sample:
                    print(f"   #{ai_post['post_id']}: {ai_post['title'][:60]}...")
                    print(f"      ğŸ¯ Status: {ai_post['processing_status']}")
                    print(f"      ğŸ§  AI Model: {ai_post['ai_model']}")
                    print(f"      ğŸ“Š AI Content: {ai_post['ai_content_length']} chars")
                    print(
                        f"      ğŸ–¼ï¸ Has Image: {'YES' if ai_post['image_url'] else 'NO'}"
                    )
                    print()
            else:
                print("ğŸ¤– AI PROCESSED POSTS: ChÆ°a cÃ³ posts nÃ o Ä‘Æ°á»£c AI xá»­ lÃ½")

            cursor.close()

        except Error as e:
            print(f"âŒ Lá»—i hiá»ƒn thá»‹ sample data: {e}")

    def list_tool_capabilities(self):
        """Liá»‡t kÃª kháº£ nÄƒng cá»§a tool"""
        print(f"\nğŸ› ï¸ KHáº¢ NÄ‚NG Cá»¦A TOOL AI CONTENT PROCESSOR")
        print("=" * 60)

        capabilities = {
            "ğŸ”„ Data Processing": [
                "âœ… Káº¿t ná»‘i MySQL database (localhost:3308)",
                "âœ… Äá»c posts tá»« báº£ng 'posts'",
                "âœ… Lá»c posts chÆ°a Ä‘Æ°á»£c AI xá»­ lÃ½",
                "âœ… Batch processing vá»›i progress tracking",
                "âœ… Error handling vÃ  retry logic",
            ],
            "ğŸ¤– AI Integration": [
                "âœ… OpenAI GPT-3.5-turbo content rewriting",
                "âœ… SEO optimization (meta_title, meta_description)",
                "âœ… Content improvement vÃ  restructuring",
                "âœ… Keyword enhancement tá»± nhiÃªn",
                "âœ… JSON structured output",
            ],
            "ğŸ¨ Image Generation": [
                "âœ… DALL-E 3 image generation",
                "âœ… 1024x1024 high quality images",
                "âœ… Smart image prompts from content",
                "âœ… Auto-generate image descriptions",
                "âœ… Image URL storage trong database",
            ],
            "ğŸ“Š Database Management": [
                "âœ… Auto-create tables náº¿u chÆ°a cÃ³",
                "âœ… Safe INSERT with ON DUPLICATE KEY",
                "âœ… Processing status tracking",
                "âœ… Foreign key constraints",
                "âœ… UTF8MB4 full Unicode support",
            ],
            "âš™ï¸ System Features": [
                "âœ… Command line interface",
                "âœ… Interactive menu system",
                "âœ… Comprehensive logging",
                "âœ… Statistics vÃ  reporting",
                "âœ… Configurable delays vÃ  limits",
            ],
            "ğŸ¯ Processing Options": [
                "âœ… Single post testing",
                "âœ… Batch processing vá»›i limits",
                "âœ… Full database processing",
                "âœ… Resume tá»« checkpoint",
                "âœ… Custom delay giá»¯a requests",
            ],
        }

        for category, features in capabilities.items():
            print(f"\n{category}:")
            for feature in features:
                print(f"   {feature}")

    def show_usage_examples(self):
        """Hiá»ƒn thá»‹ vÃ­ dá»¥ sá»­ dá»¥ng"""
        print(f"\nğŸ’¡ CÃCH Sá»¬ Dá»¤NG TOOL")
        print("=" * 40)

        examples = {
            "ğŸ¯ Command Line Usage": [
                "python ai_content_processor.py stats",
                "python ai_content_processor.py single",
                "python ai_content_processor.py batch 5 1.0",
                "python ai_content_processor.py batch 20 2.0",
            ],
            "ğŸ® Interactive Menu": [
                "python ai_content_processor.py",
                "  â†’ Chá»n 1: Xá»­ lÃ½ táº¥t cáº£ posts",
                "  â†’ Chá»n 2: Xá»­ lÃ½ sá»‘ posts giá»›i háº¡n",
                "  â†’ Chá»n 3: Xem thá»‘ng kÃª",
                "  â†’ Chá»n 4: Test 1 post",
            ],
            "ğŸ“ˆ Monitoring & Stats": [
                "Xem tá»•ng sá»‘ posts: stats command",
                "Track processing progress: progress bar",
                "Check errors: log files",
                "Performance metrics: processing speed",
            ],
        }

        for category, items in examples.items():
            print(f"\n{category}:")
            for item in items:
                print(f"   {item}")

    def estimate_processing_potential(self):
        """Æ¯á»›c tÃ­nh kháº£ nÄƒng xá»­ lÃ½"""
        print(f"\nğŸ“Š Æ¯á»šC TÃNH Xá»¬ LÃ")
        print("=" * 40)

        try:
            cursor = self.connection.cursor(dictionary=True)

            cursor.execute("SELECT COUNT(*) as total FROM posts")
            total_posts = cursor.fetchone()["total"]

            cursor.execute("SELECT COUNT(*) as processed FROM posts_ai")
            processed_posts = cursor.fetchone()["processed"]

            remaining = total_posts - processed_posts

            # Cost estimates
            cost_per_post_text = 0.02  # GPT-3.5-turbo
            cost_per_post_image = 0.04  # DALL-E 3
            total_cost_per_post = cost_per_post_text + cost_per_post_image

            print(f"ğŸ“Š HIá»†N TRáº NG:")
            print(f"   ğŸ’¾ Total posts: {total_posts}")
            print(f"   âœ… Processed: {processed_posts}")
            print(f"   â³ Remaining: {remaining}")

            print(f"\nğŸ’° Æ¯á»šC TÃNH CHI PHÃ:")
            print(f"   ğŸ¤– Text processing: ~${cost_per_post_text:.3f}/post")
            print(f"   ğŸ¨ Image generation: ~${cost_per_post_image:.3f}/post")
            print(f"   ğŸ“Š Total per post: ~${total_cost_per_post:.3f}/post")
            print(
                f"   ğŸ¯ Cost for {remaining} remaining: ~${remaining * total_cost_per_post:.2f}"
            )

            print(f"\nâ±ï¸ Æ¯á»šC TÃNH THá»œI GIAN:")
            avg_time_per_post = 15  # seconds (based on previous test)
            total_time_remaining = remaining * avg_time_per_post
            hours = total_time_remaining / 3600
            print(f"   â° ~{avg_time_per_post}s per post")
            print(f"   ğŸ• Total time for {remaining} posts: ~{hours:.1f} hours")
            print(f"   ğŸ“… With 1s delay: ~{(remaining * 16)/3600:.1f} hours")

            cursor.close()

        except Error as e:
            print(f"âŒ Lá»—i Æ°á»›c tÃ­nh: {e}")

    def list_project_files(self):
        """Liá»‡t kÃª files trong project"""
        print(f"\nğŸ“ PROJECT FILES")
        print("=" * 40)

        important_files = {
            "ğŸ¯ Core Files": [
                "ai_content_processor.py - Main AI processor",
                "config.py - OpenAI API configuration",
                "requirements.txt - Python dependencies",
            ],
            "ğŸ”„ Backup & Restore": [
                "simple_restore.py - Restore from backup CSV",
                "restore_from_backup.py - Advanced restore",
                "PROJECT_RESTORED.md - Restore guide",
            ],
            "ğŸ“Š Data Files": [
                "posts.csv - Backup CSV data",
                "ai_processing_*.log - Processing logs",
                "Database: mydb (localhost:3308)",
            ],
            "ğŸ“š Documentation": [
                "README.md - Project overview",
                "QUICK_REFERENCE.md - Quick commands",
                "Various guides and explanations",
            ],
        }

        for category, files in important_files.items():
            print(f"\n{category}:")
            for file in files:
                print(f"   ğŸ“„ {file}")

    def generate_summary_report(self):
        """Táº¡o bÃ¡o cÃ¡o tá»•ng káº¿t"""
        print(f"\nğŸ‰ Tá»”NG Káº¾T CUá»I CÃ™NG")
        print("=" * 50)

        try:
            cursor = self.connection.cursor(dictionary=True)

            cursor.execute("SELECT COUNT(*) as total FROM posts")
            total = cursor.fetchone()["total"]

            cursor.execute("SELECT COUNT(*) as processed FROM posts_ai")
            processed = cursor.fetchone()["processed"]

            cursor.close()

            print(f"ğŸ¯ Dá»° ÃN AI CONTENT PROCESSOR:")
            print(f"   âœ… Status: Fully Operational")
            print(f"   ğŸ—„ï¸ Database: MySQL Connected")
            print(f"   ğŸ¤– AI: OpenAI GPT-3.5 + DALL-E 3")
            print(f"   ğŸ“Š Data: {total} posts ({processed} processed)")

            print(f"\nğŸš€ Sáº´N SÃ€NG:")
            print(f"   âœ… Tool hoáº¡t Ä‘á»™ng hoÃ n háº£o")
            print(f"   âœ… Data Ä‘Æ°á»£c restore tá»« backup")
            print(f"   âœ… AI processing tested successfully")
            print(f"   âœ… Image generation working")

            print(f"\nğŸ’ NEXT STEPS:")
            print(f"   ğŸ¯ Cháº¡y: python ai_content_processor.py")
            print(f"   ğŸ”„ Process remaining {total - processed} posts")
            print(f"   ğŸ“ˆ Scale up for production")

        except Error as e:
            print(f"âŒ Lá»—i táº¡o report: {e}")

    def close(self):
        """ÄÃ³ng káº¿t ná»‘i"""
        if self.connection and self.connection.is_connected():
            self.connection.close()


def main():
    """Main function"""
    print("ğŸ” Tá»”NG Káº¾T TOÃ€N Bá»˜ Dá»° ÃN AI CONTENT PROCESSOR")
    print("=" * 70)
    print(f"ğŸ“… Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    try:
        summary = ProjectSummary()

        # Cháº¡y táº¥t cáº£ phÃ¢n tÃ­ch
        summary.analyze_data_structure()
        summary.analyze_current_data()
        summary.show_sample_data()
        summary.list_tool_capabilities()
        summary.show_usage_examples()
        summary.estimate_processing_potential()
        summary.list_project_files()
        summary.generate_summary_report()

        summary.close()

        print(f"\nâœ… HOÃ€N THÃ€NH Tá»”NG Káº¾T!")
        print("ğŸš€ Tool sáºµn sÃ ng sá»­ dá»¥ng!")

    except Exception as e:
        print(f"âŒ Lá»—i: {e}")


if __name__ == "__main__":
    main()
